{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV,\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "file_path = \"/workspaces/ADS-504-02-Group-7-Machine-Learning-and-Deep-Learning-for-Data-Science/nvda_2018.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Correct column names\n",
    "correct_column_names = [\n",
    "    \"time\",\n",
    "    \"open\",\n",
    "    \"high\",\n",
    "    \"low\",\n",
    "    \"close\",\n",
    "    \"PlotCandle (Open)\",\n",
    "    \"PlotCandle (High)\",\n",
    "    \"PlotCandle (Low)\",\n",
    "    \"PlotCandle (Close)\",\n",
    "    \"VWAP\",\n",
    "    \"Upper Band #1\",\n",
    "    \"Lower Band #1\",\n",
    "    \"Upper Band #2\",\n",
    "    \"Lower Band #2\",\n",
    "    \"Upper Band #3\",\n",
    "    \"Lower Band #3\",\n",
    "    \"MidLine\",\n",
    "    \"ImpulseMACD\",\n",
    "    \"ImpulseHisto\",\n",
    "    \"ImpulseMACDSignal\",\n",
    "    \"RSI\",\n",
    "    \"Regular Bullish Label\",\n",
    "    \"Regular Bullish\",\n",
    "    \"Hidden Bullish Label\",\n",
    "    \"Hidden Bullish\",\n",
    "    \"Regular Bearish Label\",\n",
    "    \"Regular Bearish\",\n",
    "    \"Hidden Bearish Label\",\n",
    "    \"Hidden Bearish\",\n",
    "]\n",
    "data.columns = correct_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64589/1479925790.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Handle outliers\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "data = data.clip(lower=Q1 - 1.5 * IQR, upper=Q3 + 1.5 * IQR, axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "data.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "data[\"target\"] = data[\"close\"] - data[\"open\"]\n",
    "data[\"target_t+1\"] = data[\"target\"].shift(-1)\n",
    "data[\"day_of_week\"] = data[\"time\"].apply(lambda x: pd.to_datetime(x).weekday())\n",
    "data[\"morning_afternoon\"] = data[\"time\"].apply(\n",
    "    lambda x: \"morning\" if pd.to_datetime(x).hour < 12 else \"afternoon\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag Features\n",
    "for lag in range(1, 4):\n",
    "    data[f\"close_lag_{lag}\"] = data[\"close\"].shift(lag)\n",
    "\n",
    "# Rolling Statistics\n",
    "data[\"close_rolling_mean_5\"] = data[\"close\"].rolling(window=5).mean()\n",
    "data[\"close_rolling_std_5\"] = data[\"close\"].rolling(window=5).std()\n",
    "\n",
    "# Drop unused columns\n",
    "columns_to_drop = [\n",
    "    \"Regular Bullish\",\n",
    "    \"Regular Bullish Label\",\n",
    "    \"Hidden Bullish\",\n",
    "    \"Hidden Bullish Label\",\n",
    "    \"Regular Bearish\",\n",
    "    \"Regular Bearish Label\",\n",
    "    \"Hidden Bearish\",\n",
    "    \"Hidden Bearish Label\",\n",
    "]\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Convert categorical features to numerical\n",
    "data = pd.get_dummies(\n",
    "    data, columns=[\"day_of_week\", \"morning_afternoon\"], drop_first=True\n",
    ")\n",
    "\n",
    "# Create the target variable: close - open\n",
    "data[\"target\"] = data[\"close\"] - data[\"open\"]\n",
    "data[\"target_t+1\"] = data[\"target\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN introduced by the shift\n",
    "data.dropna(subset=[\"target_t+1\"], inplace=True)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = data.drop(columns=[\"time\", \"close\", \"target\", \"target_t+1\"])\n",
    "y = data[\"target_t+1\"]\n",
    "\n",
    "# Ensure alignment of X and y\n",
    "X = X.iloc[:-1]\n",
    "y = y.iloc[:-1]\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "lr_model = LinearRegression()\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "# Hyperparameter tuning for XGBoost\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [3, 6, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    xgb_model, param_grid_xgb, n_iter=20, cv=5, scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search_xgb.fit(X_train_scaled, y_train)\n",
    "best_xgb_model = random_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.03268531525885849, R2: -0.02549761202444545\n",
      "Random Forest MSE: 0.03406158721616393, R2: -0.0686779697641624\n",
      "XGBoost MSE: 0.03195201926499244, R2: -0.002490543416994395\n",
      "Best XGBoost Parameters: {'subsample': 0.8, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "XGBoost 5-fold CV R2: -0.0001264826480337433\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "best_rf_model.fit(X_train_scaled, y_train)\n",
    "best_xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "rf_predictions = best_rf_model.predict(X_test_scaled)\n",
    "xgb_predictions = best_xgb_model.predict(X_test_scaled)\n",
    "\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "xgb_mse = mean_squared_error(y_test, xgb_predictions)\n",
    "xgb_r2 = r2_score(y_test, xgb_predictions)\n",
    "\n",
    "print(f\"Linear Regression MSE: {lr_mse}, R2: {lr_r2}\")\n",
    "print(f\"Random Forest MSE: {rf_mse}, R2: {rf_r2}\")\n",
    "print(f\"XGBoost MSE: {xgb_mse}, R2: {xgb_r2}\")\n",
    "print(f\"Best XGBoost Parameters: {random_search_xgb.best_params_}\")\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores_xgb = cross_val_score(\n",
    "    best_xgb_model, X_train_scaled, y_train, cv=5, scoring=\"r2\"\n",
    ")\n",
    "print(f\"XGBoost 5-fold CV R2: {np.mean(cv_scores_xgb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
