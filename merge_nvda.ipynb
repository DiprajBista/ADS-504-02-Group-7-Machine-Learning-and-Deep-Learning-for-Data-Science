{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiprajBista/ADS-504-02-Group-7-Machine-Learning-and-Deep-Learning-for-Data-Science/blob/main/merge_nvda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t6I-gTxvaeIr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQxLl59nYNl8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pssefjPsYNl9"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "file_path = \"/workspaces/ADS-504-02-Group-7-Machine-Learning-and-Deep-Learning-for-Data-Science/nvda_2018.csv\"\n",
        "data = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ythRLdWFYNl9"
      },
      "outputs": [],
      "source": [
        "# Correct column names\n",
        "correct_column_names = [\n",
        "    \"time\",\n",
        "    \"open\",\n",
        "    \"high\",\n",
        "    \"low\",\n",
        "    \"close\",\n",
        "    \"PlotCandle (Open)\",\n",
        "    \"PlotCandle (High)\",\n",
        "    \"PlotCandle (Low)\",\n",
        "    \"PlotCandle (Close)\",\n",
        "    \"VWAP\",\n",
        "    \"Upper Band #1\",\n",
        "    \"Lower Band #1\",\n",
        "    \"Upper Band #2\",\n",
        "    \"Lower Band #2\",\n",
        "    \"Upper Band #3\",\n",
        "    \"Lower Band #3\",\n",
        "    \"MidLine\",\n",
        "    \"ImpulseMACD\",\n",
        "    \"ImpulseHisto\",\n",
        "    \"ImpulseMACDSignal\",\n",
        "    \"RSI\",\n",
        "    \"Regular Bullish Label\",\n",
        "    \"Regular Bullish\",\n",
        "    \"Hidden Bullish Label\",\n",
        "    \"Hidden Bullish\",\n",
        "    \"Regular Bearish Label\",\n",
        "    \"Regular Bearish\",\n",
        "    \"Hidden Bearish Label\",\n",
        "    \"Hidden Bearish\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OACncmmlYNl9",
        "outputId": "0d055387-e519-474c-dcfc-eeef4cd12a7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_59960/2382185470.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data.fillna(method='ffill', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Handle outliers\n",
        "Q1 = data.quantile(0.25)\n",
        "Q3 = data.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "data = data.clip(lower=Q1 - 1.5 * IQR, upper=Q3 + 1.5 * IQR, axis=1)\n",
        "\n",
        "# Handle missing values\n",
        "data.fillna(method=\"ffill\", inplace=True)\n",
        "\n",
        "# Feature Engineering\n",
        "data[\"target\"] = data[\"close\"] - data[\"open\"]\n",
        "data[\"target_t+1\"] = data[\"target\"].shift(-1)\n",
        "data[\"day_of_week\"] = data[\"time\"].apply(lambda x: pd.to_datetime(x).weekday())\n",
        "data[\"morning_afternoon\"] = data[\"time\"].apply(\n",
        "    lambda x: \"morning\" if pd.to_datetime(x).hour < 12 else \"afternoon\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xQoMBCPYNl9"
      },
      "outputs": [],
      "source": [
        "# Lag Features\n",
        "for lag in range(1, 4):\n",
        "    data[f\"close_lag_{lag}\"] = data[\"close\"].shift(lag)\n",
        "\n",
        "# Rolling Statistics\n",
        "data[\"close_rolling_mean_5\"] = data[\"close\"].rolling(window=5).mean()\n",
        "data[\"close_rolling_std_5\"] = data[\"close\"].rolling(window=5).std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWdaVQH4YNl9"
      },
      "outputs": [],
      "source": [
        "# Drop unused columns\n",
        "columns_to_drop = [\n",
        "    \"Regular Bullish\",\n",
        "    \"Regular Bullish Label\",\n",
        "    \"Hidden Bullish\",\n",
        "    \"Hidden Bullish Label\",\n",
        "    \"Regular Bearish\",\n",
        "    \"Regular Bearish Label\",\n",
        "    \"Hidden Bearish\",\n",
        "    \"Hidden Bearish Label\",\n",
        "]\n",
        "data.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Convert categorical features to numerical\n",
        "data = pd.get_dummies(\n",
        "    data, columns=[\"day_of_week\", \"morning_afternoon\"], drop_first=True\n",
        ")\n",
        "\n",
        "# Create the target variable: close - open\n",
        "data[\"target\"] = data[\"close\"] - data[\"open\"]\n",
        "data[\"target_t+1\"] = data[\"target\"].shift(-1)\n",
        "\n",
        "# Handle NaN introduced by the shift\n",
        "data.dropna(subset=[\"target_t+1\"], inplace=True)\n",
        "\n",
        "# Extract features and target variable\n",
        "X = data.drop(columns=[\"time\", \"close\", \"target\", \"target_t+1\"])\n",
        "y = data[\"target_t+1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JtTYWGCYNl-"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Ensure alignment of X and y\n",
        "X = X.iloc[:-1]\n",
        "y = y.iloc[:-1]\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_imputed, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlYi3AKRYNl-"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Initialize models\n",
        "lr_model = LinearRegression()\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
        "\n",
        "# Hyperparameter tuning for XGBoost\n",
        "param_grid_xgb = {\n",
        "    \"n_estimators\": [50, 100, 200],\n",
        "    \"max_depth\": [3, 6, 10],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "random_search_xgb = RandomizedSearchCV(\n",
        "    xgb_model, param_grid_xgb, n_iter=10, cv=3, scoring=\"r2\", n_jobs=-1, random_state=42\n",
        ")\n",
        "random_search_xgb.fit(X_train_scaled, y_train)\n",
        "best_xgb_model = random_search_xgb.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPefJekSYNl-",
        "outputId": "29bd987b-9366-4300-c599-8e592978bf8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression MSE: 0.030076782101481455, R2: -0.024117995763985656\n",
            "Random Forest MSE: 0.03158111454399169, R2: -0.07534069375036512\n",
            "XGBoost MSE: 0.02939647834490979, R2: -0.0009535722116214007\n",
            "Best XGBoost Parameters: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.01}\n",
            "XGBoost 5-fold CV R2: 0.0012670863222378204\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Assuming X_train_scaled, X_test_scaled, y_train, y_test, and random_search_xgb are already defined\n",
        "\n",
        "# Initialize models\n",
        "lr_model = LinearRegression()\n",
        "best_rf_model = RandomForestRegressor(random_state=42)\n",
        "best_xgb_model = xgb.XGBRegressor(**random_search_xgb.best_params_)\n",
        "\n",
        "# Train models\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "best_rf_model.fit(X_train_scaled, y_train)\n",
        "best_xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate models\n",
        "lr_predictions = lr_model.predict(X_test_scaled)\n",
        "rf_predictions = best_rf_model.predict(X_test_scaled)\n",
        "xgb_predictions = best_xgb_model.predict(X_test_scaled)\n",
        "\n",
        "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
        "lr_r2 = r2_score(y_test, lr_predictions)\n",
        "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
        "rf_r2 = r2_score(y_test, rf_predictions)\n",
        "xgb_mse = mean_squared_error(y_test, xgb_predictions)\n",
        "xgb_r2 = r2_score(y_test, xgb_predictions)\n",
        "\n",
        "print(f\"Linear Regression MSE: {lr_mse}, R2: {lr_r2}\")\n",
        "print(f\"Random Forest MSE: {rf_mse}, R2: {rf_r2}\")\n",
        "print(f\"XGBoost MSE: {xgb_mse}, R2: {xgb_r2}\")\n",
        "print(f\"Best XGBoost Parameters: {random_search_xgb.best_params_}\")\n",
        "\n",
        "# Cross-Validation Scores\n",
        "cv_scores_xgb = cross_val_score(\n",
        "    best_xgb_model, X_train_scaled, y_train, cv=5, scoring=\"r2\", n_jobs=-1\n",
        ")\n",
        "print(f\"XGBoost 5-fold CV R2: {np.mean(cv_scores_xgb)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYxnsbfLYNmA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}